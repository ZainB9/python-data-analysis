{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data from https://www.basketball-reference.com/teams/CHI/2024.html...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# List of URLs\n",
    "urls = [\n",
    "    \"https://www.basketball-reference.com/teams/CHI/2024.html\",\n",
    "    \"https://www.basketball-reference.com/teams/LAL/2024.html\",\n",
    "    \"https://www.basketball-reference.com/teams/BOS/2024.html\",\n",
    "    \"https://www.basketball-reference.com/teams/BRK/2024.html\",\n",
    "    \"https://www.basketball-reference.com/teams/TOR/2024.html\",\n",
    "    \"https://www.basketball-reference.com/teams/PHI/2024.html\",\n",
    "    \"https://www.basketball-reference.com/teams/NYK/2024.html\",\n",
    "    \"https://www.basketball-reference.com/teams/CLE/2024.html\",\n",
    "    \"https://www.basketball-reference.com/teams/DET/2024.html\",\n",
    "    \"https://www.basketball-reference.com/teams/IND/2024.html\",\n",
    "    \"https://www.basketball-reference.com/teams/MIL/2024.html\",\n",
    "    \"https://www.basketball-reference.com/teams/WAS/2024.html\",\n",
    "    \"https://www.basketball-reference.com/teams/ATL/2024.html\",\n",
    "    \"https://www.basketball-reference.com/teams/ORL/2024.html\",\n",
    "    \"https://www.basketball-reference.com/teams/MIA/2024.html\",\n",
    "    \"https://www.basketball-reference.com/teams/CHO/2024.html\",\n",
    "    \"https://www.basketball-reference.com/teams/MIN/2024.html\",\n",
    "    \"https://www.basketball-reference.com/teams/OKC/2024.html\",\n",
    "    \"https://www.basketball-reference.com/teams/DEN/2024.html\",\n",
    "    \"https://www.basketball-reference.com/teams/POR/2024.html\",\n",
    "    \"https://www.basketball-reference.com/teams/UTA/2024.html\",\n",
    "    \"https://www.basketball-reference.com/teams/LAC/2024.html\",\n",
    "    \"https://www.basketball-reference.com/teams/GSW/2024.html\",\n",
    "    \"https://www.basketball-reference.com/teams/PHO/2024.html\",\n",
    "    \"https://www.basketball-reference.com/teams/SAC/2024.html\",\n",
    "    \"https://www.basketball-reference.com/teams/MEM/2024.html\",\n",
    "    \"https://www.basketball-reference.com/teams/NOP/2024.html\",\n",
    "    \"https://www.basketball-reference.com/teams/HOU/2024.html\",\n",
    "    \"https://www.basketball-reference.com/teams/SAS/2024.html\",\n",
    "    \"https://www.basketball-reference.com/teams/DAL/2024.html\"\n",
    "    # Add more team URLs as needed\n",
    "]\n",
    "\n",
    "user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "\n",
    "def scrape_stats(url):\n",
    "    headers = {'User-Agent': user_agent}\n",
    "    \n",
    "    logging.info(f\"Attempting to scrape data from {url}\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=30)\n",
    "        logging.info(f\"Received response with status code: {response.status_code}\")\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            table = soup.find('table', {'id': 'per_game'})\n",
    "            \n",
    "            if table:\n",
    "                columns_of_interest = {\n",
    "                    \"player\": \"Player\", \"g\": \"G\", \"trb_per_g\": \"TRB\",\n",
    "                    \"ast_per_g\": \"AST\", \"stl_per_g\": \"STL\", \"blk_per_g\": \"BLK\",\n",
    "                    \"tov_per_g\": \"TOV\", \"pts_per_g\": \"PTS\"\n",
    "                }\n",
    "                \n",
    "                rows = []\n",
    "                for row in table.tbody.find_all('tr'):\n",
    "                    row_data = {col_name: row.find('td', {'data-stat': stat}).text.strip() \n",
    "                                for stat, col_name in columns_of_interest.items() \n",
    "                                if row.find('td', {'data-stat': stat})}\n",
    "                    if row_data:\n",
    "                        rows.append(row_data)\n",
    "                \n",
    "                df = pd.DataFrame(rows)\n",
    "                logging.info(f\"Successfully extracted data for {len(df)} players.\")\n",
    "                return df\n",
    "            else:\n",
    "                logging.warning(\"Table not found on the webpage.\")\n",
    "                return pd.DataFrame()\n",
    "        else:\n",
    "            logging.error(f\"Failed to retrieve the webpage. Status code: {response.status_code}\")\n",
    "            return pd.DataFrame()\n",
    "    except requests.Timeout:\n",
    "        logging.error(\"Request timed out after 30 seconds.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred: {str(e)}\")\n",
    "    \n",
    "    return pd.DataFrame()\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for url in urls:\n",
    "    df = scrape_stats(url)\n",
    "    if not df.empty:\n",
    "        all_data.append(df)\n",
    "    \n",
    "    # Wait between 60 to 90 seconds before the next request\n",
    "    delay = random.uniform(60, 90)\n",
    "    logging.info(f\"Waiting {delay:.2f} seconds before the next request...\")\n",
    "    time.sleep(delay)\n",
    "\n",
    "if all_data:\n",
    "    final_df = pd.concat(all_data, ignore_index=True)\n",
    "    print(final_df)\n",
    "    final_df.to_csv('nba_per_game_stats.csv', index=False)\n",
    "    logging.info(\"Data saved to 'nba_per_game_stats.csv'\")\n",
    "else:\n",
    "    logging.warning(\"No data was scraped. Please check the logs for errors.\")\n",
    "\n",
    "logging.info(\"Scraping process completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <div class=\"table_container tabbed current is_setup\" id=\"div_per_game\">\t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
